{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gCo3M4pofxU"
      },
      "source": [
        "Imports + dataset + loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S5453w5olzt",
        "outputId": "996d4138-fd5b-4070-df9f-f85a1831b139"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(\".\", train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(\".\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9ohZQPNrKc7"
      },
      "source": [
        "VGG11 Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JfyPlBBjrOSB"
      },
      "outputs": [],
      "source": [
        "class VGG11(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    #Layers in the feature extraction\n",
        "    @staticmethod\n",
        "    def feature_extraction (input, output, pool=False):\n",
        "      layers = [nn.Conv2d(input, output, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(output),\n",
        "                nn.ReLU()]\n",
        "\n",
        "      if pool:\n",
        "        layers.append(nn.MaxPool2d(2))\n",
        "      return nn.Sequential(*layers)\n",
        "\n",
        "    #feature exctraction following VGG11 architecure\n",
        "    self.features = nn.Sequential(\n",
        "          feature_extraction(1, 64, pool=True),   # → 16×16\n",
        "          feature_extraction(64, 128, pool=True),   # → 8×8\n",
        "          feature_extraction(128, 256, pool=False),  # → 8×8\n",
        "          feature_extraction(256, 256, pool=True),   # → 4×4\n",
        "          feature_extraction(256, 512, pool=False),  # → 4×4\n",
        "          feature_extraction(512, 512, pool=True),   # → 2×2\n",
        "          feature_extraction(512, 512, pool=False),  # → 2×2\n",
        "          feature_extraction(512, 512, pool=True)    # → 1×1\n",
        "    )\n",
        "\n",
        "    #classification with fully connected layers and dropout\n",
        "    self.classifier = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(512, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "          nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "          nn.Linear(4096, 10)\n",
        "    )\n",
        "\n",
        "  #Forward propogation\n",
        "  def forward (self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnkzyHifwF1O"
      },
      "source": [
        "Model + Loss Function + update rule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1o6-YGUTwHBN"
      },
      "outputs": [],
      "source": [
        "#Sets device to GPU is available otherwise uses CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Initializes model to use\n",
        "model = VGG11().to(device)\n",
        "\n",
        "#loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "#update rule\n",
        "update_rule = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHSOSQAUxGFd"
      },
      "source": [
        "Training + predicting + output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vjy60jw8xF1O"
      },
      "outputs": [],
      "source": [
        "def run(train_loader, test_loader, model, loss_function, update_rule):\n",
        "    max_epochs = 10\n",
        "    data = {\n",
        "        \"train_loss\": [], \"train_accuracy\": [],\n",
        "        \"test_loss\":  [], \"test_accuracy\":  []\n",
        "    }\n",
        "\n",
        "    # Trains and predicts for max_epochs\n",
        "    for epoch in range(0, max_epochs):\n",
        "        # ---------------------- Training -----------------------------------\n",
        "        model.train()\n",
        "        total_loss = correct = total = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            update_rule.zero_grad()  # Sets gradients to zero\n",
        "\n",
        "            # Forward -> loss -> backward -> update\n",
        "            outputs = model(images)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            update_rule.step()\n",
        "\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            predictions = outputs.argmax(1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_loss = total_loss / total\n",
        "        train_accuracy = 100 * correct / total\n",
        "        data[\"train_loss\"].append(train_loss)\n",
        "        data[\"train_accuracy\"].append(train_accuracy)\n",
        "\n",
        "        # ---------------------- Prediction --------------------------------\n",
        "        model.eval()\n",
        "        total_loss = correct = total = 0\n",
        "        with torch.no_grad():  # No gradients needed\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Forward -> compute loss\n",
        "                outputs = model(images)\n",
        "                loss = loss_function(outputs, labels)\n",
        "\n",
        "                total_loss += loss.item() * labels.size(0)\n",
        "                predictions = outputs.argmax(1)\n",
        "                correct += (predictions == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        test_loss = total_loss / total\n",
        "        test_accuracy = 100 * correct / total\n",
        "        data[\"test_loss\"].append(test_loss)\n",
        "        data[\"test_accuracy\"].append(test_accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{max_epochs} done\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zxDzsG7zay_P",
        "outputId": "bf6dca89-f36b-4baf-cb4c-fd7a208dff93"
      },
      "outputs": [],
      "source": [
        "#Q3.1,2,3\n",
        "run(train_loader, test_loader, model, loss_function, update_rule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlS_v7BPd5QY"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
